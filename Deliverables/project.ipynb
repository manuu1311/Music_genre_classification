{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20403,"status":"ok","timestamp":1710682994481,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"hZpAjQeTjGr5","outputId":"4d049e55-5a30-4bd1-81c8-b57bc3d5a469"},"outputs":[],"source":["#!pip install visualkeras"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5406,"status":"ok","timestamp":1710682999881,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"n4za33qDfZhY"},"outputs":[],"source":["import tensorflow as tf\n","#from visualkeras import layered_view\n","prelu=tf.keras.layers.ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710685241497,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"FD2RrUa6ffaf"},"outputs":[],"source":["def encoder_block(inputs, num_filters,dropout_rate,pen):\n","    x = tf.keras.layers.Conv2D(num_filters,3, padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(pen))(inputs)\n","    x = prelu()(x)\n","    x = tf.keras.layers.Conv2D(num_filters,3, padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(pen))(x)\n","    x = prelu()(x)\n","    x=tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n","    p = tf.keras.layers.MaxPool2D(pool_size = (2,2))(x)\n","    return x,p\n","\n","def decoder_block(inputs, skip_features, num_filters,dropout_rate,pen):\n","    # deconvolution\n","    x = tf.keras.layers.Conv2DTranspose(num_filters,(3,3),strides=(2,2), padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(pen))(inputs)\n","    x = tf.keras.layers.concatenate([x, skip_features])\n","\n","    x = tf.keras.layers.Conv2D(num_filters,3, padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(pen))(x)\n","    x = prelu()(x)\n","    x = tf.keras.layers.Conv2D(num_filters,3, padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(pen))(x)\n","    x = prelu()(x)\n","    return x\n","\n","\n","def tower(inputs,num_filters,dropout_rate,pen):\n","    tower_1 = tf.keras.layers.Conv2D(num_filters, 3, padding='same',kernel_regularizer=tf.keras.regularizers.l2(pen))(inputs)\n","    tower_1=prelu()(tower_1)\n","    tower_1 = tf.keras.layers.MaxPooling2D(2, padding='same')(tower_1)\n","\n","    tower_2 = tf.keras.layers.Conv2D(num_filters, 3, padding='same',kernel_regularizer=tf.keras.regularizers.l2(pen))(inputs)\n","    tower_2 = tf.keras.layers.MaxPooling2D(2, padding='same')(tower_2)\n","\n","    merged=tf.keras.layers.concatenate([tower_1,tower_2])\n","    return merged"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1710685243392,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"gNAV-RZvfpic"},"outputs":[],"source":["def unet_model(input_shape = (512, 512, 3), num_filters=256, num_classes = 10, dropout_rate=0.2,lam=0.001):\n","    inputs = tf.keras.layers.Input(input_shape)\n","\n","    #       BLOCK 1\n","    #convolution with prelu\n","    c1 = tf.keras.layers.Conv2D(int(num_filters/32),3, padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(lam))(inputs)\n","    c1 = prelu()(c1)\n","    c1 = tf.keras.layers.MaxPool2D(2)(c1)\n","    c1=tf.keras.layers.BatchNormalization()(c1)\n","    c1 = tf.keras.layers.Dropout(rate=dropout_rate)(c1)\n","    #downsample - contracting path\n","    f1,p1=encoder_block(c1,int(num_filters/16),dropout_rate,lam)\n","    f2,p2=encoder_block(p1,int(num_filters/8),dropout_rate,lam)\n","    f3,p3=encoder_block(p2,int(num_filters/4),dropout_rate,lam)\n","    #bottleneck\n","    bottleneck = tf.keras.layers.Conv2D(int(num_filters/2), 3, padding = \"same\", kernel_regularizer=tf.keras.regularizers.l2(lam))(p3)\n","    bottleneck=prelu()(bottleneck)\n","    #upsample - expanding path\n","    u4 = decoder_block(bottleneck, f3, int(num_filters/4),dropout_rate,lam)\n","    u5 = decoder_block(u4, f2, int(num_filters/8),dropout_rate,lam)\n","    u6 = decoder_block(u5, f1, int(num_filters/16),dropout_rate,lam)\n","\n","    #forward fine grained features with deconvolution\n","    features= tf.keras.layers.Conv2DTranspose(int(num_filters/32),3, padding = 'same',kernel_regularizer=tf.keras.regularizers.l2(lam))(u6)\n","    #parallel convolutions\n","    pc1=tower(features,int(num_filters/16),dropout_rate,lam)\n","    pc1 = tf.keras.layers.Dropout(rate=dropout_rate)(pc1)\n","    pc2=tower(pc1,int(num_filters/8),dropout_rate,lam)\n","    pc2 = tf.keras.layers.Dropout(rate=dropout_rate)(pc2)\n","    pc3=tower(pc2,int(num_filters/4),dropout_rate,lam)\n","    pc3 = tf.keras.layers.Dropout(rate=dropout_rate)(pc3)\n","    pc4=tower(pc3,int(num_filters/2),dropout_rate,lam)\n","    pc4 = tf.keras.layers.Dropout(rate=dropout_rate)(pc4)\n","\n","\n","    flat = tf.keras.layers.Flatten()(pc4)\n","\n","\n","\n","    #       OUTPUT\n","    outputs = tf.keras.layers.Dense(num_classes, activation = \"softmax\")(flat)\n","\n","    model = tf.keras.models.Model(inputs = inputs, outputs = outputs, name = 'U-Net')\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## MODEL 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1813,"status":"ok","timestamp":1710685247558,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"2SrdF1g4fvoR","outputId":"650a5a53-a540-4973-d301-95bf328f589e"},"outputs":[],"source":["#create model\n","model = unet_model(input_shape=(128, 320, 1),num_filters=512, num_classes=10)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2180,"status":"ok","timestamp":1710683019234,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"DLdOZtBmiA2T","outputId":"2d18513c-5ee7-4402-b47a-45ed227eb85c"},"outputs":[],"source":["layered_view(model, legend = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39455,"status":"ok","timestamp":1710683063125,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"Ibi-z2evp0be"},"outputs":[],"source":["#get dataset on colab\n","import requests\n","import os\n","\n","fname = \"music.zip\"\n","url = \"https://osf.io/drjhb/download\"\n","\n","if not os.path.isfile(fname):\n","  try:\n","    r = requests.get(url)\n","  except requests.ConnectionError:\n","    print(\"!!! Failed to download data !!!\")\n","  else:\n","    if r.status_code != requests.codes.ok:\n","      print(\"!!! Failed to download data !!!\")\n","    else:\n","      with open(fname, \"wb\") as fid:\n","        fid.write(r.content)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15899,"status":"ok","timestamp":1710683079022,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"sNUAalB_p3Cg"},"outputs":[],"source":["from zipfile import ZipFile\n","#extract the dataset\n","with ZipFile(fname, 'r') as zipObj:\n","  zipObj.extractall()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"elapsed":12116,"status":"ok","timestamp":1710683091136,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"kbHLEH_E6AoM","outputId":"034e5606-3654-46cc-a842-8e68d53abf92"},"outputs":[],"source":["import librosa\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Convert sound wave to mel spectrogram. trying this on a sample audio\n","sample_path = 'Data/genres_original/hiphop/hiphop.00031.wav'\n","\n","y, sr = librosa.load(sample_path)\n","\n","S = librosa.feature.melspectrogram(y=y, sr=sr)\n","S_DB = librosa.amplitude_to_db(S**2)\n","plt.figure(figsize=(15, 5))\n","librosa.display.specshow(S_DB, sr=sr, hop_length=512,\n","                         x_axis='time', y_axis='log')\n","plt.colorbar()\n","plt.title(\"Mel spectrogram\", fontsize=20)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data Augmentation\n","\n","'''\n","Noise addition using normal distribution with mean = 0 and std =1\n","Permissible noise factor value = x > 0.004\n","'''\n","\n","def noise_addition(data,zero_value=0.0, noise_factor=0.03):\n","    noise = np.random.random(data.shape)\n","    augmented_data = data + noise_factor * noise\n","    #augmented_data = augmented_data.astype(type(data[0]))\n","    return augmented_data\n","\n","'''\n","Time shifting the wave\n","Permissible factor values = sr/10\n","'''\n","\n","def time_shift(data,zero_value=0.0):\n","    shift = np.random.randint(-3,4)*50\n","    augmented_data = np.roll(data, shift)\n","    return augmented_data\n","\n","'''\n","Time-stretching the wave\n","Permissible factor values = 0 < x < 1.0\n","'''\n","\n","def time_stretch(data,zero_value=0.0, speed_factor=2):\n","    samples = np.array_split(data, 3)\n","    data1=librosa.effects.time_stretch(samples[0], rate=1/speed_factor)\n","    data2=librosa.effects.time_stretch(samples[1], rate=speed_factor)\n","    data3=librosa.effects.time_stretch(samples[2], rate=speed_factor)\n","    return np.concatenate([data1,data2,data3])\n","\n","'''\n","Pitch shifting of wav\n","Permissible factor values = -5 <= x <= 5\n","'''\n","\n","def pitch_shift(data,zero_value=0.0,factor=4):\n","    return librosa.effects.pitch_shift(data, sr=22000, n_steps=factor)\n","\n","#time mask\n","def time_mask(y,zero_value=0.0):\n","    zero_value=np.min(y)\n","    x=y.shape[1]\n","    step=50\n","    idxs=np.random.randint(0,x-step,size=(3))\n","    for idx in idxs:\n","        y[:,idx:idx+step]=zero_value\n","    return y\n","\n","\n","'''\n","Augmenting the data\n","'''\n","\n","def augment_data(data,zero_value=0.0,tresh=0.35):\n","    funs=[noise_addition,time_shift,time_mask]\n","    for i in range(len(funs)):\n","        p=np.random.random()\n","        if p<tresh:\n","            data=funs[i](data,zero_value)\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig,axs=plt.subplots(3,2,figsize=(12,8))\n","axs=axs.flatten()\n","sample_path = 'Data/genres_original/hiphop/hiphop.00031.wav'\n","y,sr=librosa.load(sample_path)\n","\n","#original\n","spec = librosa.feature.melspectrogram(y=y, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[0].set_title(\"Mel spectrogram\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[0])\n","\n","#time mask\n","# Fix: Ensure 'y' array has the expected dimensions for time_mask function\n","yhat=time_mask(y[np.newaxis, :])\n","spec = librosa.feature.melspectrogram(y=y, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[1].set_title(\"Time mask\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512, x_axis='time', y_axis='log', ax=axs[1])\n","\n","#wn\n","yhat=noise_addition(y)\n","spec = librosa.feature.melspectrogram(y=yhat, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[2].set_title(\"White noise\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[2])\n","\n","#time shift\n","yhat=time_shift(y)\n","spec = librosa.feature.melspectrogram(y=yhat, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[3].set_title(\"Time shift\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[3])\n","\n","#pitch shift\n","yhat=pitch_shift(y)\n","spec = librosa.feature.melspectrogram(y=yhat, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[4].set_title(\"Pitch shift\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[4])\n","\n","#time stretch\n","yhat=time_stretch(y)\n","spec = librosa.feature.melspectrogram(y=yhat, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[5].set_title(\"Time stretch\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[5])\n","\n","for ax in axs:\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","plt.subplots_adjust(hspace=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#randomly apply transformations\n","#run this block multiple times to see the different possibilities \n","sample_path = 'Data/genres_original/hiphop/hiphop.00031.wav'\n","y,sr=librosa.load(sample_path)\n","\n","fig,axs=plt.subplots(1,2,figsize=(30,5))\n","\n","#augmented\n","yhat=augment_data(y)\n","spec = librosa.feature.melspectrogram(y=yhat, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","axs[1].set_title(\"Augmented spectrogram\", fontsize=20)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[1])\n","\n","#original\n","axs[0].set_title(\"Original spectrogram\", fontsize=20)\n","spec = librosa.feature.melspectrogram(y=y, sr=sr)\n","spec = librosa.amplitude_to_db(spec**2)\n","librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log',ax=axs[0])\n","\n","for ax in axs:\n","    ax.set_xticks([])\n","    ax.set_yticks([])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710683091137,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"YIDaRGQttlgk","outputId":"1c7c17dc-43ef-42f8-907e-686f98fda6f3"},"outputs":[],"source":["#testing with different audio samples,it is possible to see that the resulting\n","#spectrogram is not always the same size (the audios differ for some milliseconds)\n","#so, it is necessary to only consider the size 128x1290 (minimum size that all\n","#spectrograms have) and disregard other values to keep it consistent\n","print(S_DB.shape)\n","S_DB=S_DB[None,:128,:1290,None]\n","S_DB.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1710683096311,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"bPGC8i9TrRWr","outputId":"95575199-caf8-4e8f-e4cb-a5a38e9b88bd"},"outputs":[],"source":["#all genres within the dataset\n","data_path = 'Data/genres_original/'\n","genres = [folder for folder in os.listdir(data_path)]\n","genres"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1710683098830,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"yrXQrz-Suecb"},"outputs":[],"source":["#corrupted audio\n","os.remove('Data/genres_original/jazz/jazz.00054.wav')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":59176,"status":"ok","timestamp":1710684133411,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"2OOq3pLOBiW_"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","#preprocessing function to get the spectrogram from the audio\n","def load_spec(y):\n","    spectrogram=librosa.feature.melspectrogram(y=y,sr=sr)\n","    specdb = librosa.amplitude_to_db(spectrogram**2)\n","    specdb=specdb[:128,:1280]\n","    return specdb\n","\n","\n","# data preparation\n","Xpy = []\n","y = []\n","data_path = 'Data/genres_original/'\n","genres = [folder for folder in os.listdir(data_path)]\n","for i, genre in enumerate(genres):\n","    genre_dir = os.path.join(data_path, genre)\n","    for filename in os.listdir(genre_dir):\n","        file_path = os.path.join(genre_dir, filename)\n","        audio, sr = librosa.load(file_path, sr=22050)\n","        Xpy.append(audio)\n","        y.append(i)\n","\n","X = np.array(Xpy)\n","y = np.array(y)\n","zeroval=0\n","#WE COULD TRY: data normalization\n","#TYPE 1\n","#mean=np.mean(X)\n","#s=np.std(X)\n","#X=(X-mean)/s\n","#print(mean,s)\n","#zeroval=(0-mean)/s\n","\n","#TYPE 2\n","val_max=np.max(X)\n","X=X/val_max\n","print(val_max)\n","\n","# Split dataset into train and test sets\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","X_train=[np.split(x,4) for x in X_train]\n","X_train=np.array([piece for song in X_train for piece in song])\n","X_valid=np.array([np.split(x,4) for x in X_valid])\n","X_valid=np.array([piece for song in X_valid for piece in song])\n","y_train=[[i,i,i,i] for i in y_train]\n","y_train=np.array([piece for song in y_train for piece in song])\n","y_valid=[[i,i,i,i] for i in y_valid]\n","y_valid=np.array([piece for song in y_valid for piece in song])\n","#shuffle the pieces\n","X_train,y_train=shuffle(X_train,y_train,random_state=7)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#check to see if training set is balanced\n","print([y_train[y_train==i].shape[0] for i in range(10)])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#training with whole dataset causes colab to crash because of ram\n","#so we need to use a generator\n","class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, x_data, y_data, batch_size,training=False):\n","        self.training=training\n","        self.x_data = x_data\n","        self.y_data = y_data\n","        self.batch_size = batch_size\n","        self.indexes = np.arange(len(self.x_data))\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.x_data) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","        batch_indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        batch_x = self.x_data[batch_indexes]\n","        specs=np.zeros((self.batch_size,128,320))\n","        for i in range(len(batch_x)):\n","            if self.training:\n","                batch_x[i]=augment_data(batch_x[i],zeroval)\n","            #spec = load_spec(batch_x[i])\n","            #specs[i,:,:320] = spec[:,:320]  # Ensure the shape is (128,320)\n","        batch_y = self.y_data[batch_indexes]\n","        return specs[..., np.newaxis], batch_y  # Add a new dimension at the end\n","\n","trainset = DataGenerator(X_train, y_train, batch_size=4,training=False)\n","validset = DataGenerator(X_valid, y_valid, batch_size=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1710685275037,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"Yj26JuI4uDEr"},"outputs":[],"source":["model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59570,"status":"ok","timestamp":1710685335680,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"vjOzQg2pt83_","outputId":"20bcc1e4-3127-4fb0-f434-4248bb8cd731"},"outputs":[],"source":["history = model.fit(trainset, epochs=25, validation_data=validset)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1710684029097,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"w7oMrBZ2qLKS"},"outputs":[],"source":["import json\n","with open('training_history.json', 'w') as f:\n","    json.dump(history.history, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOBGwM99USjI"},"outputs":[],"source":["#compute mean spectrograms for each genre\n","mean_spectrograms=[]\n","for i, genre in enumerate(genres):\n","    genre_dir = os.path.join(data_path, genre)\n","    genre_spectrograms=[]\n","    for filename in os.listdir(genre_dir):\n","        file_path = os.path.join(genre_dir, filename)\n","        audio = librosa.load_audio(file_path, target_shape=(512, 512))\n","        genre_spectrograms.append(audio)\n","    genre_spectrograms=np.array(genre_spectrograms)\n","    mean_spectrograms.append(np.mean(genre_spectrograms,axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"elapsed":7749,"status":"ok","timestamp":1710510765495,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"G-ld6KtPVfN3","outputId":"955131f0-57f3-4ba6-cc66-7e6657f64e8b"},"outputs":[],"source":["fig, axs = plt.subplots(ncols = 5, nrows = 2, figsize = (20,6))\n","axs = axs.reshape((-1,))\n","\n","for i,genre in enumerate(genres):\n","  spec=np.reshape(mean_spectrograms[i],(128,1290))\n","  librosa.display.specshow(spec, sr=sr, hop_length=512,x_axis='time', y_axis='log', ax=axs[i])\n","  axs[i].set_title(genre, fontsize=16)\n","  #plt.colorbar(im, ax=ax)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117062,"status":"ok","timestamp":1710685166680,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"F0WzJhUFpSpE","outputId":"668d5a49-f6ee-41eb-88c3-98fd9a1e8e55"},"outputs":[],"source":["#get prediction for all dataset\n","yhat_train=[]\n","truey_train=[]\n","yhat_valid=[]\n","truey_valid=[]\n","for i,song in enumerate(X_train):\n","  song = np.expand_dims(song, axis=0)\n","  song = np.expand_dims(song, axis=-1)\n","  res=np.argmax(model.predict(song))\n","  yhat_train.append(res)\n","  truey_train.append(y_train[i])\n","\n","for i,song in enumerate(X_valid):\n","  song = np.expand_dims(song, axis=0)\n","  song = np.expand_dims(song, axis=-1)\n","  res=np.argmax(model.predict(song))\n","  yhat_valid.append(res)\n","  truey_valid.append(y_valid[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":242,"status":"ok","timestamp":1710685172966,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"vLViyOgOuRlB"},"outputs":[],"source":["#save results to file\n","truey_train=[int(x) for x in truey_train]\n","yhat_train=[int(x) for x in yhat_train]\n","with open('true_train.json','w') as f:\n","  json.dump(truey_train,f)\n","with open('predicted_train.json','w') as f:\n","  json.dump(yhat_train,f)\n","\n","truey_valid=[int(x) for x in truey_valid]\n","yhat_valid=[int(x) for x in yhat_valid]\n","with open('true_valid.json','w') as f:\n","  json.dump(truey_valid,f)\n","with open('predicted_valid.json','w') as f:\n","  json.dump(yhat_valid,f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1710683356482,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"qjqyMnuQrGxn","outputId":"da519cad-7380-428d-ae5f-229250578d4d"},"outputs":[],"source":["yhat_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3909,"status":"ok","timestamp":1710683321173,"user":{"displayName":"Emanuele P","userId":"13316066353384296773"},"user_tz":-60},"id":"MDqnRFdDqgTW","outputId":"1ad0b195-8757-4430-fe64-bda66d4bfba3"},"outputs":[],"source":["import numpy as np\n","prova = np.ones((1,128,320))\n","model.predict(prova)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOI2ZPLcwwO6aX4MKhq2ZKw","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
